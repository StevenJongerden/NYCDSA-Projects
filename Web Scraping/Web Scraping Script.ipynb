{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install package in anaconda prompt \n",
    "# pip install requests requests[socks]\n",
    "\n",
    "#Load packages and prepare the header statement\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os, sys\n",
    "import os.path\n",
    "import urllib.request\n",
    "from stem import Signal\n",
    "from stem.control import Controller\n",
    "\n",
    "#Prepare Header for www.funda.nl\n",
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'Access-Control-Request-Headers': 'content-type',\n",
    "    'Accept': '*/*',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Start tor.exe and Privoxy.exe to enable IP Rotation\n",
    "\n",
    "class ConnectionManager:\n",
    "    def __init__(self):\n",
    "        self.new_ip = \"0.0.0.0\"\n",
    "        self.old_ip = \"0.0.0.0\"\n",
    "        self.new_identity()\n",
    "\n",
    "    @classmethod\n",
    "    def _get_connection(self):\n",
    "        \"\"\"\n",
    "        TOR new connection\n",
    "        \"\"\"\n",
    "        with Controller.from_port(port=9051) as controller:\n",
    "            controller.authenticate(password=\"1234\")\n",
    "            controller.signal(Signal.NEWNYM)\n",
    "            controller.close()\n",
    "\n",
    "    @classmethod\n",
    "    def _set_url_proxy(self):\n",
    "        \"\"\"\n",
    "        Request to URL through local proxy\n",
    "        \"\"\"\n",
    "        proxy_support = urllib.request.ProxyHandler({\"http\": \"127.0.0.1:8118\"})\n",
    "        opener = urllib.request.build_opener(proxy_support)\n",
    "        urllib.request.install_opener(opener)\n",
    "\n",
    "    @classmethod\n",
    "    def request(self, url):\n",
    "        \"\"\"\n",
    "        TOR communication through local proxy\n",
    "        :param url: web page to parser\n",
    "        :return: request\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self._set_url_proxy()\n",
    "            request = urllib.request.Request(url, None, {\n",
    "                'User-Agent': \"Mozilla/5.0 (X11; Linux x86_64) \"\n",
    "                              \"AppleWebKit/535.11 (KHTML, like Gecko) \"\n",
    "                              \"Ubuntu/10.10 Chromium/17.0.963.65 \"\n",
    "                              \"Chrome/17.0.963.65 Safari/535.11\"})\n",
    "            request = urllib.request.urlopen(request)\n",
    "            return request\n",
    "        except urllib.request.HTTPError:\n",
    "            return e.message\n",
    "\n",
    "    def new_identity(self):\n",
    "        \"\"\"\n",
    "        new connection with new IP\n",
    "        \"\"\"\n",
    "        # First Connection\n",
    "        if self.new_ip == \"0.0.0.0\":\n",
    "            self._get_connection()\n",
    "            self.new_ip = self.request(\"http://icanhazip.com/\").read()\n",
    "        else:\n",
    "            self.old_ip = self.new_ip\n",
    "            self._get_connection()\n",
    "            self.new_ip = self.request(\"http://icanhazip.com/\").read()\n",
    "\n",
    "        seg = 0\n",
    "\n",
    "        # If we get the same ip, we'll wait 5 seconds to request a new IP\n",
    "        while self.old_ip == self.new_ip:\n",
    "            time.sleep(5)\n",
    "            seg += 5\n",
    "            print (\"Waiting to obtain new IP: %s Seconds\" % seg                                   ,  end=\"\\r\")\n",
    "            self.new_ip = self.request(\"http://icanhazip.com/\").read()\n",
    "        \n",
    "cm = ConnectionManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% Complete, Scraping process complete in04:20:25 185.38.14.215\n"
     ]
    }
   ],
   "source": [
    "#Get the list of links from the search page for all search pages, saved in a csv file per row. \n",
    "#Number of pages= 8443\n",
    "#Information is always stored in linklist, even when the process gets terminated \n",
    "\n",
    "try:\n",
    "    not(os.path.exists('houselinks.csv'))\n",
    "except:  \n",
    "    os.remove('houselinks.csv')\n",
    "\n",
    "#Set Starting IP Adress:\n",
    "cm.new_identity()\n",
    "    \n",
    "with open('houselinks.csv', 'w') as csvfile:\n",
    "    url_link_list = csv.writer(csvfile)    \n",
    "    linklist = []\n",
    "    averagetime = []\n",
    "    \n",
    "    ###IMPORTANT### Set the number to scrape\n",
    "    numbertoscrape = 8443\n",
    "    \n",
    "    #Start of home link scraper\n",
    "    for i in range(2,numbertoscrape):\n",
    "        try:\n",
    "            start = datetime.now()\n",
    "            response = requests.get('http://www.funda.nl/koop/heel-nederland/p'+str(i)+'/', headers=headers).text\n",
    "            Funda = BeautifulSoup(response, 'html.parser')\n",
    "            Houses = Funda.find_all('div', {'class': 'search-result-header'})\n",
    "            for tag in Houses:\n",
    "                link = [tag.a.get('href')]\n",
    "                for tag in link:\n",
    "                    linklist = linklist + link\n",
    "\n",
    "            #IP Randomizer\n",
    "            if i % 50 == 0:\n",
    "                cm.new_identity()\n",
    "\n",
    "            #Calculate Time\n",
    "            end = datetime.now()\n",
    "            averagetime += [(end - start).total_seconds()]\n",
    "            meantime = np.mean(averagetime)\n",
    "            timeleft = str(datetime.timedelta(seconds=(numbertoscrape-i * meantime)))\n",
    "\n",
    "            #print percentage and time remaining\n",
    "            print(str(round((i/numbertoscrape)*100,2))+'% Complete' + ', Time remaining: ' + str(timeleft)+ \", Scraping on IP adress \"+ str(cm.new_ip)[2:15],  end=\"\\r\")\n",
    "        except:\n",
    "            cm.new_identity()\n",
    "            \n",
    "    url_link_list.writerow(linklist)\n",
    "    \n",
    "print(\"100.0% Complete, Scraping process complete in\"+str(time.strftime(\"%H:%M:%S\", time.gmtime(sum(averagetime)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare the list of url's to houses in the variable linkelist\n",
    "with open('houselinks.csv', 'r') as f:\n",
    "    linkelist = list(csv.reader(f))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126488"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the number of houses in the linkelist file\n",
    "len(linkelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Home site scraper, developed to scrape all elements of one particular home. \n",
    "elementschar = ['Oorspronkelijke vraagprijs', 'Aangeboden sinds','Soort bouw', 'Soort dak', 'Aantal kamers',\n",
    "                'Aantal badkamers', 'Badkamervoorzieningen', 'Aantal woonlagen', 'Voorzieningen',\n",
    "                'Verwarming', 'Cv-ketel', 'Eigendomssituatie', 'Ligging', 'Ligging tuin', 'Tuin', 'Balkon/dakterras',\n",
    "                'Schuur/berging', 'Soort garage', 'Soort parkeergelegenheid']\n",
    "elementsint = ['Vraagprijs', 'Bouwjaar', 'Woonoppervlakte', 'Overige inpandige ruimte', 'Gebouwgebonden buitenruimte',\n",
    "                  'Externe bergruimte', 'Perceeloppervlakte', 'Inhoud', 'Capagiteit']\n",
    "\n",
    "def scrapehouse(i):\n",
    "    dic = {} \n",
    "    for x in elementschar:\n",
    "        try:\n",
    "            dic[str(x)] = House.find('div', class_='object-primary').find('dt', text=x).find_next_sibling('dd').text[:-2]\n",
    "        except:\n",
    "            dic[str(x)] = \"\"      \n",
    "    for x in elementsint:\n",
    "        try:\n",
    "            dic[str(x)] = int(''.join(re.findall('\\d+', House.find('div', class_='object-primary').find('dt', text=x).find_next_sibling('dd').text)))\n",
    "        except:\n",
    "            dic[str(x)] = \"\"     \n",
    "    try:\n",
    "        dic['Isolatie'] = House.find('div', class_='object-primary').find('dt', text='Isolatie').find_next_sibling('dd').text[:-12]\n",
    "    except:\n",
    "        dic['Isolatie'] = \"\"\n",
    "    try:\n",
    "        dic['Voorlopig energielabel'] = House.find('div', class_='object-primary').find('dt', text='Voorlopig energielabel').find_next_sibling('dd').text[1]\n",
    "    except:\n",
    "        dic['Voorlopig energielabel'] = \"\"\n",
    "    try:\n",
    "        dic['Adress'] = House.find('span', class_ ='object-header-subtitle').text\n",
    "    except:\n",
    "        dic['Adress'] = \"\"   \n",
    "    try:\n",
    "        dic['Soort woonhuis'] = House.find('div', class_='object-primary').find('dt', text='Soort woonhuis').find_next_sibling('dd').text[:-12]\n",
    "    except:\n",
    "        dic['Soort woonhuis'] = \"\"     \n",
    "    if i == 0:\n",
    "        HouseData.writerow(dic.keys())\n",
    "        \n",
    "    HouseData.writerow(dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting to obtain new IP: 5 Secondss\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-ef6b62d5a5e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://www.funda.nl'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlinkelist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-432288aaeb1f>\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     41\u001b[0m                               \"Chrome/17.0.963.65 Safari/535.11\"})\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Steven Jongerden\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Steven Jongerden\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Steven Jongerden\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    641\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 642\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Steven Jongerden\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Steven Jongerden\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Steven Jongerden\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 503: Forwarding failure",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-ef6b62d5a5e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnumbertoscrape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'% Complete'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', Time remaining: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\", Scraping on IP adress \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_ip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_identity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"100.0% Complete, Scraping process complete in\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%H:%M:%S\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgmtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maveragetime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-432288aaeb1f>\u001b[0m in \u001b[0;36mnew_identity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mseg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Waiting to obtain new IP: %s Seconds\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mseg\u001b[0m                                   \u001b[1;33m,\u001b[0m  \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_ip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://icanhazip.com/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConnectionManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-432288aaeb1f>\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnew_identity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "#Open CSV File in the form of a list and allow for subsetting, move from 0 to the total lenght of the url list len(linkelist).\n",
    "#Remove old HouseInformation.csv\n",
    "#try:\n",
    "#    not(os.path.exists('HouseInformation.csv'))\n",
    "#except:  \n",
    "#    os.remove('HouseInformation.csv')\n",
    "\n",
    "#Set Starting IP Adress:\n",
    "#cm.new_identity()\n",
    "    \n",
    "#Append new information to csv in order to prevent loss of data during ip ban or filehandling errors\n",
    "with open('HouseInformation.csv', 'a', newline='') as csvfile:\n",
    "    HouseData = csv.writer(csvfile)\n",
    "    averagetime = []\n",
    "    \n",
    "    ###IMPORTANT### Set the number to scrape\n",
    "    numbertoscrape = len(linkelist)\n",
    "    \n",
    "    #Scraper loop\n",
    "    for i in range(48039,numbertoscrape):\n",
    "        try:\n",
    "            start = datetime.now()\n",
    "            response = requests.get('http://www.funda.nl'+linkelist[i], headers=headers).text\n",
    "            House = BeautifulSoup(response, 'html.parser')\n",
    "            scrapehouse(i)\n",
    "\n",
    "            #IP Randomizer\n",
    "            if i % 100 == 0:\n",
    "                cm.new_identity()\n",
    "\n",
    "            #Calculate Time\n",
    "            end = datetime.now()\n",
    "            averagetime += [(end - start).total_seconds()]\n",
    "            meantime = np.mean(averagetime)\n",
    "            timeleft = str(datetime.timedelta(seconds=(numbertoscrape-i * meantime)))\n",
    "\n",
    "            #print percentage and time remaining\n",
    "            print(str(round((i/numbertoscrape)*100,2))+'% Complete' + ', Time remaining: ' + str(timeleft)+ \", Scraping on IP adress \"+ str(cm.new_ip)[2:15],  end=\"\\r\")\n",
    "        except:\n",
    "            cm.new_identity()\n",
    "    \n",
    "print(\"100.0% Complete, Scraping process complete in\"+str(time.strftime(\"%H:%M:%S\", time.gmtime(sum(averagetime)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
