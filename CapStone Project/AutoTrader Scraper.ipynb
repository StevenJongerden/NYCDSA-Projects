{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load packages and prepare the header statement\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import datetime \n",
    "import numpy as np\n",
    "import os, sys\n",
    "import os.path\n",
    "import urllib.request\n",
    "from stem import Signal\n",
    "from stem.control import Controller\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'Access-Control-Request-Headers': 'content-type',\n",
    "    'Accept': '*/*',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Start tor.exe and Privoxy.exe to enable IP Rotation\n",
    "\n",
    "class ConnectionManager:\n",
    "    def __init__(self):\n",
    "        self.new_ip = \"0.0.0.0\"\n",
    "        self.old_ip = \"0.0.0.0\"\n",
    "        self.new_identity()\n",
    "\n",
    "    @classmethod\n",
    "    def _get_connection(self):\n",
    "        \"\"\"\n",
    "        TOR new connection\n",
    "        \"\"\"\n",
    "        with Controller.from_port(port=9051) as controller:\n",
    "            controller.authenticate(password=\"1234\")\n",
    "            controller.signal(Signal.NEWNYM)\n",
    "            controller.close()\n",
    "\n",
    "    @classmethod\n",
    "    def _set_url_proxy(self):\n",
    "        \"\"\"\n",
    "        Request to URL through local proxy\n",
    "        \"\"\"\n",
    "        proxy_support = urllib.request.ProxyHandler({\"http\": \"127.0.0.1:8118\"})\n",
    "        opener = urllib.request.build_opener(proxy_support)\n",
    "        urllib.request.install_opener(opener)\n",
    "\n",
    "    @classmethod\n",
    "    def request(self, url):\n",
    "        \"\"\"\n",
    "        TOR communication through local proxy\n",
    "        :param url: web page to parser\n",
    "        :return: request\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self._set_url_proxy()\n",
    "            request = urllib.request.Request(url, None, {\n",
    "                'User-Agent': \"Mozilla/5.0 (X11; Linux x86_64) \"\n",
    "                              \"AppleWebKit/535.11 (KHTML, like Gecko) \"\n",
    "                              \"Ubuntu/10.10 Chromium/17.0.963.65 \"\n",
    "                              \"Chrome/17.0.963.65 Safari/535.11\"})\n",
    "            request = urllib.request.urlopen(request)\n",
    "            return request\n",
    "        except urllib.request.HTTPError:\n",
    "            return e.message\n",
    "\n",
    "    def new_identity(self):\n",
    "        \"\"\"\n",
    "        new connection with new IP\n",
    "        \"\"\"\n",
    "        # First Connection\n",
    "        if self.new_ip == \"0.0.0.0\":\n",
    "            self._get_connection()\n",
    "            self.new_ip = self.request(\"http://icanhazip.com/\").read()\n",
    "        else:\n",
    "            self.old_ip = self.new_ip\n",
    "            self._get_connection()\n",
    "            self.new_ip = self.request(\"http://icanhazip.com/\").read()\n",
    "\n",
    "        seg = 0\n",
    "\n",
    "        # If we get the same ip, we'll wait 5 seconds to request a new IP\n",
    "        while self.old_ip == self.new_ip:\n",
    "            time.sleep(5)\n",
    "            seg += 5\n",
    "            print (\"Waiting to obtain new IP: %s Seconds\" % seg                                   ,  end=\"\\r\")\n",
    "            self.new_ip = self.request(\"http://icanhazip.com/\").read()\n",
    "        \n",
    "cm = ConnectionManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting to obtain new IP: 5 Seconds\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ea0688ffda6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mresponse2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.autotrader.co.uk'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinklist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mCarSpecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#Main Code \n",
    "\n",
    "#Number of pages with multiple cars \n",
    "\n",
    "dic = {}\n",
    "t = 0\n",
    "\n",
    "cm.new_identity()\n",
    "\n",
    "with open('AutoTraderLinks.csv', 'a', newline='') as csvfile:\n",
    "    AutroTraderCSV = csv.writer(csvfile)\n",
    "    averagetime = []\n",
    "\n",
    "    #Build in another for loop to incorporate the brand of the car. We can only scrape till 100 pages.\n",
    "    #Use the page indication to find the maximum number of pages.\n",
    "    #Maybe only get information from the top 10 brands up to a 1000 observations, sorted on the newests cars to get\n",
    "    #the most recent information\n",
    "    \n",
    "    #For example, Land Rover, Maza, Audi, Mercedes, Mini, Nissan, Citroen, Peugeot, Renault, Skoda, Ford,\n",
    "    #Hyundai, Toyota, Vauxhall, Jaguar, Volkswagen, Volvo and Kia. \n",
    "    \n",
    "    #Set number to scrape to the maximum number of pages or equal to 100 if the number is larger. \n",
    "    numbertoscrape = 6000\n",
    "    \n",
    "    for i in np.arange(1, numbertoscrape, 1):\n",
    "        linklist\n",
    "            \n",
    "        response = requests.get('https://www.autotrader.co.uk/car-search?sort=sponsored&radius=1500&postcode=ec1a1yx&onesearchad=Nearly%20New&page='+str(i), headers=headers).text\n",
    "        AutoTrader = BeautifulSoup(response, 'html.parser')\n",
    "        Cars = AutoTrader.find_all('a', {'class': 'listing-fpa-link'})\n",
    "        linklist = []\n",
    "        for tag in Cars:\n",
    "            link = [tag.get('href')]\n",
    "            for tag in link:\n",
    "                 linklist = linklist + link\n",
    "        linklist = np.unique(linklist[5:43]) \n",
    "        \n",
    "        if i % 2 == 0:\n",
    "                cm.new_identity()\n",
    "        \n",
    "        for x in np.arange(1,10):\n",
    "            start = datetime.datetime.now()\n",
    "            sleep(randint(1,6))\n",
    "            response2 = requests.get('https://www.autotrader.co.uk'+str(linklist[x]), headers=headers).text\n",
    "            CarSpecs = BeautifulSoup(response2, 'html.parser')\n",
    "\n",
    "            try:\n",
    "                dic['CarName'] = CarSpecs.find(\"span\", {\"class\": \"pricetitle__advertTitle\"}).text.split(',')[0].strip()\n",
    "            except:\n",
    "                dic['CarName'] = \"\"   \n",
    "            try:\n",
    "                dic['CarPrice'] = CarSpecs.find(\"section\", {\"class\": \"priceTitle__price gui-advert-price\"}).text.strip()\n",
    "            except:\n",
    "                dic['CarPrice'] = \"\"    \n",
    "            try:\n",
    "                dic['WebRating'] = CarSpecs.find(\"div\", {\"class\": \"starRating__number\"}).text.strip()\n",
    "            except:\n",
    "                dic['WebRating'] = \"\" \n",
    "                        \n",
    "            TableCar = CarSpecs.find_all(\"ul\", {\"class\": \"keyFacts__list\"})\n",
    "            for tag in TableCar:\n",
    "                spec = tag.text\n",
    "                spec = spec.splitlines() \n",
    "\n",
    "            try:\n",
    "                dic['Year'] = spec[1] \n",
    "            except:\n",
    "                dic['Year'] = \"\" \n",
    "            try:\n",
    "                dic['CarType'] = spec[2] \n",
    "            except:\n",
    "                dic['CarType'] = \"\" \n",
    "            try:\n",
    "                dic['Miles'] = spec[3] \n",
    "            except:\n",
    "                dic['Miles'] = \"\" \n",
    "            try:\n",
    "                dic['Transmission'] = spec[4] \n",
    "            except:\n",
    "                dic['Transmission'] = \"\" \n",
    "            try:\n",
    "                dic['EngineDiscplacement'] = spec[5]\n",
    "            except:\n",
    "                dic['EngineDiscplacement'] = \"\" \n",
    "            try:\n",
    "                dic['FuelType'] = spec[6]\n",
    "            except:\n",
    "                dic['FuelType'] = \"\" \n",
    "                \n",
    "                \n",
    "            RunningCosts = CarSpecs.find_all(\"div\", {\"class\": \"fpaSpecifications__description\"})\n",
    "            RC = []\n",
    "            for tag in RunningCosts:\n",
    "                RC = RC + [tag.text]\n",
    "            \n",
    "            try:\n",
    "                dic['UrbanMPG'] = RC[0]\n",
    "            except:\n",
    "                dic['UrbanMPG'] = \"\"\n",
    "            try:\n",
    "                dic['Extra Urban mpg'] = RC[1] \n",
    "            except:\n",
    "                dic['Extra Urban mpg'] = \"\"\n",
    "            try:    \n",
    "                dic['Average mpg'] = RC[2] \n",
    "            except:\n",
    "                dic['Average mpg'] = \"\"\n",
    "            try:\n",
    "                dic['CO2 emissions'] = RC[3] \n",
    "            except:\n",
    "                dic['CO2 emissions'] = \"\"\n",
    "            try:\n",
    "                dic['Annual Tax'] = RC[4] \n",
    "            except:\n",
    "                dic['Annual Tax'] = \"\"\n",
    "            try:\n",
    "                dic['Engine power'] = RC[5] \n",
    "            except:\n",
    "                dic['Engine power'] = \"\"\n",
    "            try:\n",
    "                dic['Engine size'] = RC[6]\n",
    "            except:\n",
    "                dic['Engine size'] = \"\"\n",
    "            try:\n",
    "                dic['Brochure Engine size'] = RC[7] \n",
    "            except:\n",
    "                dic['Brochure Engine size'] = \"\"\n",
    "            try:\n",
    "                dic['Acceleration (0-60mph)'] = RC[8] \n",
    "            except:\n",
    "                dic['Acceleration (0-60mph)'] = \"\"\n",
    "            try:\n",
    "                dic['Top speed'] = RC[9] \n",
    "            except:\n",
    "                dic['Top speed'] = \"\"\n",
    "            try:\n",
    "                dic['Drivetrain'] = RC[10] \n",
    "            except:\n",
    "                dic['Drivetrain'] = \"\"\n",
    "            try:\n",
    "                dic['Nr Doors'] = RC[11] \n",
    "            except:\n",
    "                dic['Nr Doors'] = \"\"\n",
    "            try:\n",
    "                dic['Nr Seats'] = RC[12] \n",
    "            except:\n",
    "                dic['Nr Seats'] = \"\"   \n",
    "                \n",
    "            Options = CarSpecs.find_all(\"div\", {\"class\": \"fpaSpecifications__term\"})\n",
    "            Op = []\n",
    "            for tag in Options:\n",
    "                Op = Op + [tag.text]\n",
    "\n",
    "            dic['Options'] = Op[13:]\n",
    "    \n",
    "            if t == 0:\n",
    "                AutroTraderCSV.writerow(dic.keys())\n",
    "                AutroTraderCSV.writerow(dic.values()) \n",
    "                t +=1\n",
    "            else:\n",
    "                AutroTraderCSV.writerow(dic.values())\n",
    "            \n",
    "            end = datetime.datetime.now()    \n",
    "            averagetime += [(end - start).total_seconds()]\n",
    "            meantime = np.mean(averagetime)\n",
    "            timeleft = str(datetime.timedelta(seconds=((numbertoscrape*9-((i-1)*9+x)) * meantime)))\n",
    "\n",
    "            print(str(round(((i-1)*9+x)/(numbertoscrape*9),2)*100)+'% Complete, on number :' +str((i-1)*9+x)+ ' , Time remaining: ' + str(timeleft),\" Scraping on IP adress \"+ str((cm.new_ip).strip()),end=\"\\r\")               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
